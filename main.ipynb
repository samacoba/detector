{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import cuda, Variable\n",
    "from chainer import optimizers\n",
    "import numpy as np\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CNN_deCNN(chainer.Chain):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN_deCNN, self).__init__(\n",
    "            conv1=L.Convolution2D(1, 10, 4, stride=2,pad=1),\n",
    "            conv2=L.Convolution2D(10, 25, 4, stride=2,pad=1),\n",
    "            conv3=L.Convolution2D(25, 50, 4, stride=2,pad=1),\n",
    "            conv4=L.Convolution2D(50, 100, 4, stride=2,pad=1),\n",
    "            deconv1=L.Deconvolution2D(100, 50, 4, stride=2,pad=1),           \n",
    "            deconv2=L.Deconvolution2D(50, 25, 4, stride=2,pad=1),\n",
    "            deconv3=L.Deconvolution2D(25, 10, 4, stride=2,pad=1),\n",
    "            deconv4=L.Deconvolution2D(10, 1, 4, stride=2,pad=1),\n",
    "            bn1 = L.BatchNormalization(10),\n",
    "            bn2 = L.BatchNormalization(25),\n",
    "            bn3 = L.BatchNormalization(50),\n",
    "            bn4 = L.BatchNormalization(100),\n",
    "            bn5 = L.BatchNormalization(50),\n",
    "            bn6 = L.BatchNormalization(25),\n",
    "            bn7 = L.BatchNormalization(10),\n",
    "            bn8 = L.BatchNormalization(1),\n",
    "        )\n",
    "        self.train = True\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.bn1(self.conv1(x),test=not self.train))\n",
    "        h = F.relu(self.bn2(self.conv2(h),test=not self.train))\n",
    "        h = F.relu(self.bn3(self.conv3(h),test=not self.train))\n",
    "        h = F.relu(self.bn4(self.conv4(h),test=not self.train))\n",
    "        h = F.relu(self.bn5(self.deconv1(h),test=not self.train))\n",
    "        h = F.relu(self.bn6(self.deconv2(h),test=not self.train))\n",
    "        h = F.relu(self.bn7(self.deconv3(h),test=not self.train))\n",
    "        y = F.relu(self.bn8(self.deconv4(h),test=not self.train))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__(\n",
    "            conv1=L.Convolution2D(2, 10, 4, stride=2, pad=1),\n",
    "            conv2=L.Convolution2D(10, 25, 4, stride=2, pad=1),\n",
    "            conv3=L.Convolution2D(25, 50, 4, stride=2, pad=1),\n",
    "            conv4=L.Convolution2D(50, 100, 4, stride=2, pad=1),\n",
    "            l5 = L.Linear(None, 2),\n",
    "            bn1 = L.BatchNormalization(10),\n",
    "            bn2 = L.BatchNormalization(25),\n",
    "            bn3 = L.BatchNormalization(50),\n",
    "            bn4 = L.BatchNormalization(100),\n",
    "        )\n",
    "        self.train = True\n",
    "        \n",
    "    def __call__(self, x, test=False):\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.relu(self.bn2(self.conv2(h), test=not self.train))\n",
    "        h = F.relu(self.bn3(self.conv3(h), test=not self.train))\n",
    "        h = F.relu(self.bn4(self.conv4(h), test=not self.train))\n",
    "        y = self.l5(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#モデル読み込み\n",
    "gpu = 0 # 0：gpu使用、-1：gpu不使用\n",
    "\n",
    "g_model = CNN_deCNN()\n",
    "d_model = Discriminator()\n",
    "\n",
    "if gpu >= 0:\n",
    "    cuda.check_cuda_available()\n",
    "xp = cuda.cupy if gpu >= 0 else np\n",
    "\n",
    "if gpu >= 0:\n",
    "    cuda.get_device(gpu).use()\n",
    "    g_model.to_gpu()\n",
    "    d_model.to_gpu()\n",
    "    \n",
    "g_optimizer = optimizers.Adam()\n",
    "g_optimizer.setup(g_model)\n",
    "\n",
    "d_optimizer = optimizers.Adam()\n",
    "d_optimizer.setup(d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imgAのｘとｔのデータ読み込み\n",
    "DataA = data.get_ori_data_pos_1pic(fpath = 'imgA.png')\n",
    "#imgBのxのみのデータを取得\n",
    "DataB = data.get_ori_data_x_1pic(fpath = 'imgB.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.io import gridplot, push_notebook, show, output_notebook\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "palette_256 = ['#%02x%02x%02x' %(i,i,i) for i in range(256)] #256段階で白黒表示用\n",
    "\n",
    "plt1 = figure(title = 'train N = --', x_range=[0, DataA['imgW']], y_range=[0, DataA['imgH']])\n",
    "rend1 = plt1.image(image=[np.zeros_like(DataB['x'][0][0])],x=[0], y=[0], dw=[DataA['imgW']], dh=[DataA['imgH']], palette=palette_256)\n",
    "\n",
    "plt2 = figure(title = 'count  = --', x_range=plt1.x_range, y_range=plt1.y_range)\n",
    "rend2 = plt2.image(image=[DataB['x'][0][0]],x=[0], y=[0], dw=[DataA['imgW']], dh=[DataA['imgH']], palette=palette_256)\n",
    "\n",
    "plts = gridplot([[plt1,plt2]], plot_width=400, plot_height=400)\n",
    "handle = show(plts, notebook_handle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imgAトレーニングとテスト\n",
    "batchSize = 100\n",
    "N_train = 2000\n",
    "nLoop = 100\n",
    "\n",
    "for loop in range(nLoop): \n",
    "    \n",
    "    print('loop = ' + str(loop))\n",
    "\n",
    "    #＜トレーニング＞\n",
    "    g_model.train = True\n",
    "    \n",
    "    for i in range(0, N_train, batchSize):\n",
    "        \n",
    "        #データ取得\n",
    "        DataN = data.get_data_N_rand(DataA, batchSize)        \n",
    "        x_batch = Variable(xp.asarray(DataN['x']))\n",
    "        t_batch = Variable(xp.asarray(DataN['t_core']))\n",
    "\n",
    "        #学習      \n",
    "        y_batch = g_model(x_batch)\n",
    "        \n",
    "        # 直接の場合\n",
    "\n",
    "        g_optimizer.zero_grads()\n",
    "        g_loss =  F.mean_squared_error(y_batch, t_batch)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.update()\n",
    " \n",
    "    \n",
    "\n",
    "        # pix2pixの場合\n",
    "        \"\"\"             \n",
    "        y_pair = F.hstack((x_batch, y_batch))\n",
    "        t_pair = F.hstack((x_batch, t_batch))\n",
    "        \n",
    "        y_fake = d_model(y_pair)   \n",
    "        \n",
    "        g_optimizer.zero_grads()\n",
    "        g_loss = F.softmax_cross_entropy(y_fake, Variable(xp.zeros(batchSize, dtype=np.int32)))        \n",
    "        g_loss.backward()\n",
    "        g_optimizer.update()        \n",
    "        \n",
    "        d_optimizer.zero_grads()\n",
    "        d_loss = F.softmax_cross_entropy(y_fake, Variable(xp.ones(batchSize, dtype=np.int32))) \n",
    "        y_original = d_model(t_pair)\n",
    "        d_loss += F.softmax_cross_entropy(y_original, Variable(xp.zeros(batchSize, dtype=np.int32)))         \n",
    "        d_loss.backward()\n",
    "        d_optimizer.update()\n",
    "        \"\"\" \n",
    "        \n",
    "    # ＜テスト＞\n",
    "    g_model.train = False\n",
    "    x_batch = chainer.Variable(xp.asarray(DataB['x']), volatile='on')\n",
    "    y_batch = g_model(x_batch)\n",
    "    \n",
    "    y_batch.to_cpu()\n",
    "    DataB['y'] = y_batch.data\n",
    "    DataB['y_point']= data.get_local_max_point(DataB['y'], 0.3)\n",
    " \n",
    "    print( ', y_count = ' + str(DataB['y_point'][0].sum()))\n",
    "    \n",
    "    #グラフィック表示\n",
    "    DataB['y_circle'] = data.draw_circle(DataB['y_point'])\n",
    "    img1 = DataB['y'][0][0] \n",
    "    img2 = DataB['x'][0][0] + DataB['y_circle'][0][0]\n",
    "    img1[img1>1] =1\n",
    "    img2[img2>1] =1\n",
    "    rend1.data_source.data['image'] = [img1]\n",
    "    rend2.data_source.data['image'] = [img2]\n",
    "    plt1.title.text='train N = '+ str((loop+1)*N_train)\n",
    "    plt2.title.text='count = '+ str(int(DataB['y_point'][0].sum()))\n",
    "    push_notebook(handle = handle)#表示をアップデート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
